- Understand why Google has put AI principles in place.
- Identify the need for a responsible AI practice within an organization.
- Recognize that decisions made at all stages of a project have an impact on responsible AI.
- Recognize that organizations can design AI to fit their own business needs and values.

### AI Systems
They see, understand and interact with the World. They are not infallible

Each organization develops their own AI Principles


### AI Principles at Google
- Built for everyone
- Accountable and safe
- Respects privacy
- Driven by scientific excellence


### Miscommon Misconception
- Machines are responsible for their own decisions, however people built these machines and people who use them. 

### Ethics
- Ethics is a set of principles that guide the actions of people and organizations.
- Right from wrong and fair from unfair

### Assesments and Reviews
- Assesments are done to determine if a system is ethical
- Robust processes are used to ensure that the assesment is fair and accurate



## They are a foundation that establishes what we stand for, what we build, and why we build it, and they are core to the success of our enterprise AI offerings.

### The 7 Principles of AI at Google
- AI should be socially beneficial
- AI should avoid creating or reinforcing unfair bias
- AI should be built and tested for safety
- AI should be accountable to people
- AI should incorporate privacy design principles
- AI should uphold high standards of scientific excellence
- AI should be made available for uses that accord with these principles

### Applications we will not pursue
- Technologies that cause or are likely to cause overall harm
- Weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people
- Technologies that gather or use information for surveillance that violates internationally accepted norms
- Technologies whose purpose contravenes widely accepted principles of international law and human rights